{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from random import randint\n",
    "\n",
    "dataset_path = 'dataset/econstor_2017-06-01.json'\n",
    "try:\n",
    "    df = pd.read_json(dataset_path, lines=True, encoding='utf8')\n",
    "except ValueError:\n",
    "    raise ValueError(\"The dataset file seems to be missing. Please contact Nils Witt (n.witt@zbw.eu) \\\n",
    "at ZBW to retrieve your own copy.\")\n",
    "    \n",
    "df = df[df[\"classification_jel\"].notnull()]\n",
    "df = df[df[\"abstract\"].notnull()]\n",
    "df = df[df[\"language\"].apply(lambda row: row == [\"eng\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collection compiler\n",
    "\n",
    "The collection compiler is able to generate a collection (`generate_collection`), i.e. a set of documents with at least `degree` common JEL codes. It can also generate two disjoint collections (`disjoint_collections`) where two collections don't have any JEL code in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from collections import Counter, defaultdict\n",
    "from itertools import chain\n",
    "\n",
    "class Collections():\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        self.cabinet = self._jel_cabinet()\n",
    "    \n",
    "    def _jel_cabinet(self):\n",
    "        \"\"\"\n",
    "        creates a dict whos keys are jel codes. the values are list of indices\n",
    "        of documents attached with the corresponding jel code.\n",
    "        {\n",
    "            \"N74\": [1293, 97128, ...],\n",
    "            \"O57\": [8172, 12369, ...],\n",
    "            ...\n",
    "        }\n",
    "        \"\"\"\n",
    "        jel_cabinet = defaultdict(list)\n",
    "        for idx, row in self.df.iterrows():\n",
    "            for jel_code in row['classification_jel']:\n",
    "                jel_cabinet[jel_code].append(idx)\n",
    "        return jel_cabinet\n",
    "\n",
    "    def jel_set(self, idxs):\n",
    "        \"\"\"\n",
    "        return the set of all jel codes of the documents in idxs, where each document is\n",
    "        referenced by its index\n",
    "        \"\"\"\n",
    "        return set(chain(*\n",
    "            (df.loc[idx][\"classification_jel\"] for idx in idxs)\n",
    "        ))\n",
    "        \n",
    "    def fetch_random_doc(self, degree):\n",
    "        \"\"\"\n",
    "        finds a random document with at least `degree` jel codes.\n",
    "        \"\"\"\n",
    "        num_docs = len(self.df.index)\n",
    "        rand_doc = self.df.loc[self.df.index[randint(0, num_docs - 1)]]\n",
    "        while(len(rand_doc[\"classification_jel\"]) < degree + 2): # we want a documenent \n",
    "                                                                 # with enough jel codes\n",
    "            rand_doc = self.df.loc[self.df.index[randint(0, num_docs - 1)]]\n",
    "        return rand_doc\n",
    "\n",
    "    def fetch_most_similar_docs(self, rand_doc):\n",
    "        \"\"\"\n",
    "        returns a list of documents that are most similar to `rand_doc`. The first\n",
    "        document on that list is the one that is most similar to rand_doc.\n",
    "        \"\"\"\n",
    "        friend_docs = []\n",
    "        for jel_code in rand_doc[\"classification_jel\"]:\n",
    "            friend_docs.extend(self.cabinet[jel_code])\n",
    "        return Counter(friend_docs)\n",
    "    \n",
    "    def fetch_dissimilar_doc(self, col):\n",
    "        \"\"\"\n",
    "        given a collection `col` (a list of indices) it returns a dissimilar \n",
    "        (w.r.t the JEL codes) document.\n",
    "        \"\"\"\n",
    "        return collections.disjoint_collections(col=col, size=1)[1][0]\n",
    "\n",
    "\n",
    "    def generate_collection(self, size=4, degree=1):\n",
    "        \"\"\"\n",
    "        creates an artificial collection from the pandas dataframe `df`.\n",
    "        `size` determines the number of documents in the collection while\n",
    "        `degree` is a measure of connectivitiy density. that is, for a\n",
    "        degree of x all documents share x concepts.\n",
    "        \"\"\"\n",
    "        assert degree in range(0, 11), \"unreasonable value for `degree`\"\n",
    "        \n",
    "        size_not_ok = True\n",
    "        collection = \"\"\n",
    "        while size_not_ok:\n",
    "            rand_doc = self.fetch_random_doc(degree)\n",
    "            collection = self.fetch_most_similar_docs(rand_doc)\n",
    "            if collection.most_common(size)[-1][1] >= degree:\n",
    "                size_not_ok = False\n",
    "\n",
    "        return [v for v, _ in collection.most_common(size)]\n",
    "    \n",
    "    def disjoint_collections(self, size=4, degree=1, col=None):\n",
    "        \"\"\"\n",
    "        creates two collections whose JEL codes are disjoint.\n",
    "        each collection contains `size` documents that have at least `degree`\n",
    "        common JEL codes.\n",
    "        if a `col` is passed, only the opposing collection is generated.\n",
    "        \"\"\"\n",
    "        if col is None:\n",
    "            col_a = self.generate_collection(size=size, degree=degree)\n",
    "        else:\n",
    "            col_a = col\n",
    "            \n",
    "        col_b = None\n",
    "        jels_a = self.jel_set(col_a)\n",
    "        a_b_not_disjoint = True\n",
    "        \n",
    "        while a_b_not_disjoint:\n",
    "            col_b = self.generate_collection(size=size, degree=degree)\n",
    "            jels_b = self.jel_set(col_b)\n",
    "            if jels_b.isdisjoint(jels_a):\n",
    "                a_b_not_disjoint = False\n",
    "        \n",
    "        return col_a, col_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections = Collections(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ADD import TFIDF, LSI, TextRank\n",
    "\n",
    "dataset = [d.split() for d, *rest in df[\"abstract\"]]\n",
    "tfidf = TFIDF.TFIDF(dataset)\n",
    "\n",
    "collections_compiler = Collections(df)\n",
    "\n",
    "keyword_extractors = {\"LSI\": LSI, \"TFIDF\": tfidf, \"TextRank\": TextRank}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADD property test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from collections import namedtuple\n",
    "\n",
    "class ADD_property():\n",
    "    def __init__(self):\n",
    "        self.collections_compiler = Collections(df)\n",
    "    \n",
    "    def _name(self, obj):\n",
    "        return obj.__name__ if hasattr(obj, \"__name__\") else obj.__module__\n",
    "    \n",
    "    def _idx_to_text(self, idx):\n",
    "        \"\"\"\n",
    "        returns the list of words from the document referred to by `idx`\n",
    "        \"\"\"\n",
    "        return df.loc[idx][\"abstract\"][0].split()\n",
    "\n",
    "    def _keywords(self, imp, idxs):\n",
    "        \"\"\"\n",
    "        returns the set of all keywords in the documents in `idxs`. `idxs` is a list\n",
    "        of indices.\n",
    "        `imp` is the implementation of the keyword extraction algorithm. it must have\n",
    "        a `keywords` method that takes a list of words and return the keywords.\n",
    "        \"\"\"\n",
    "        return set(chain(*(imp.keywords(self._idx_to_text(idx)) for idx in idxs)))\n",
    "    \n",
    "    def _keyword_sets(self, imp, doc_a, doc_z, lib):\n",
    "        \"\"\"\n",
    "        return three keywords sets. (1) the keywords of `doc_a`, (2) the keywords\n",
    "        of `doc_z` and (3) the keywords of lib.\n",
    "        the keywords are generated `imp.keywords()`.\n",
    "        \"\"\"\n",
    "        return (self._keywords(imp, [doc_a]), \n",
    "            self._keywords(imp, [doc_z]), \n",
    "            self._keywords(imp, lib))\n",
    "\n",
    "    def _setup_ADD_scenario(self, size=5, degree=2):\n",
    "        \"\"\"\n",
    "        returns a three-tupel containing (1) a document (say A), (2) a document\n",
    "        dissimilar to A (say Z) and collection of documents similar to A.\n",
    "        \"\"\"\n",
    "        doc_a, *collection = \\\n",
    "            self.collections_compiler.generate_collection(size=size, degree=degree)\n",
    "        doc_z = self.collections_compiler.fetch_dissimilar_doc(collection)\n",
    "        return doc_a, doc_z, collection\n",
    "\n",
    "    def _intersection_difference_ratio(self, kws_doc, kws_collection):\n",
    "        \"\"\"\n",
    "        computes the ratio of the size of the intersection between `kws_doc` and\n",
    "        `kws_collection` and the size of `kws_doc`.\n",
    "        \"\"\"\n",
    "        num_kws_doc = len(kws_doc)\n",
    "        intersection_size = len(kws_doc.intersection(kws_collection))\n",
    "        return (intersection_size+1) / (num_kws_doc+1)\n",
    "    \n",
    "    def run_test(self, implementations, collection_size=10, degree=5):\n",
    "        kw_ratios = namedtuple(\"kw_ratios\", ['a_to_col', 'z_to_col'])\n",
    "        doc_a, doc_z, lib = self._setup_ADD_scenario(size=collection_size, degree=degree)\n",
    "        results = {}\n",
    "        \n",
    "        for imp in implementations:\n",
    "            kw_a, kw_z, kw_lib = self._keyword_sets(imp, doc_a, doc_z, lib)\n",
    "            results[self._name(imp)] = kw_ratios(\n",
    "                self._intersection_difference_ratio(kw_a, kw_lib), \\\n",
    "                self._intersection_difference_ratio(kw_z, kw_lib))\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_test = ADD_property()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_experiment(sample_size=100, collection_size=5, degree=3):\n",
    "    bucket = []\n",
    "    for _ in tqdm(range(sample_size), mininterval=50):\n",
    "        bucket.append(add_test.run_test((LSI, tfidf, TextRank), \n",
    "            collection_size=collection_size, degree=degree))\n",
    "    return bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def reduce_results(raw_data, sample_size):\n",
    "    results = pd.DataFrame(index=raw_data[0].keys(), columns=(\"a_to_col\", \"z_to_col\"))\n",
    "    results = results.fillna(0)\n",
    "\n",
    "    for result in raw_data:\n",
    "        for k, v in result.items():\n",
    "            results.loc[k, \"a_to_col\"] += v.a_to_col\n",
    "            results.loc[k, \"z_to_col\"] += v.z_to_col\n",
    "\n",
    "    results = results / sample_size\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some experiments for Comparability and Differentiability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 300\n",
    "cs = 3\n",
    "degree = 1\n",
    "raw_results = execute_experiment(sample_size=ss, collection_size=cs, degree=degree)\n",
    "reduce_results(raw_results, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 100\n",
    "cs = 10\n",
    "degree = 1\n",
    "raw_results = execute_experiment(sample_size=ss, collection_size=cs, degree=degree)\n",
    "reduce_results(raw_results, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 100\n",
    "cs = 10\n",
    "degree = 5\n",
    "raw_results = execute_experiment(sample_size=ss, collection_size=cs, degree=degree)\n",
    "reduce_results(raw_results, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 100\n",
    "cs = 15\n",
    "degree = 2\n",
    "raw_results = execute_experiment(sample_size=ss, collection_size=cs, degree=degree)\n",
    "reduce_results(raw_results, ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = 100\n",
    "cs = 15\n",
    "degree = 5\n",
    "raw_results = execute_experiment(sample_size=ss, collection_size=cs, degree=degree)\n",
    "reduce_results(raw_results, ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for Diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map all keywords to their respective documents. Do that for all implementations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "\n",
    "def idx_to_text(idx):\n",
    "    return df.loc[idx][\"abstract\"][0].split()\n",
    "\n",
    "# find all keywords\n",
    "doc_kw_mapping = pd.DataFrame(index=df.index, columns=keyword_extractors.keys())\n",
    "\n",
    "for idx, (extractor_name, extractor) in tqdm(\n",
    "    product(df.index, keyword_extractors.items()), mininterval=10):\n",
    "    doc_kw_mapping.loc[idx, extractor_name] = extractor.keywords(idx_to_text(idx))\n",
    "    \n",
    "# remove nan entries\n",
    "doc_kw_mapping = doc_kw_mapping[doc_kw_mapping[\"LSI\"].notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create keyword blacklist. the most n most frequent keywords are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor\n",
    "\n",
    "drop_n_most_frequent = .01\n",
    "kw_blacklist = defaultdict(set)\n",
    "for col in doc_kw_mapping:\n",
    "    kw_cnt = Counter(chain(*doc_kw_mapping[col].values))\n",
    "    n_most_common = floor(len(kw_cnt.most_common()) * .01)\n",
    "    kw_blacklist[col] = set((kw for kw, _ in kw_cnt.most_common(n_most_common)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate the jel-code/keyword mapping matrix. Initially only filled with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_blacklisted_kws(kwds, col):\n",
    "    return list(set(kwds).difference(kw_blacklist[col]))\n",
    "\n",
    "def extract_keywords(idx, extractor):\n",
    "    return remove_blacklisted_kws(doc_kw_mapping.loc[idx, extractor], extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jel_codes = set(chain(*[row['classification_jel'] for idx, row in df.iterrows()]))\n",
    "\n",
    "jel_kwcnt = dict([(ex, None) for ex in keyword_extractors.keys()])\n",
    "for col in doc_kw_mapping:\n",
    "    kw_set = set(chain(*doc_kw_mapping[col].values))\n",
    "    kw_set = remove_blacklisted_kws(kw_set, col)\n",
    "    \n",
    "    jel_kwcnt[col] = pd.DataFrame(index=jel_codes, columns=kw_set)\n",
    "    jel_kwcnt[col] = jel_kwcnt[col].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate jel-code/keyword mapping matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in doc_kw_mapping:\n",
    "    for k, v in tqdm(doc_kw_mapping[col].iteritems(), total=len(df), mininterval=10):\n",
    "        jel_codes = df.loc[k][\"classification_jel\"]\n",
    "        #kws = doc_kw_mapping.loc[k, col]\n",
    "        #kws = remove_blacklisted_kws(kws, col)\n",
    "        kws = extract_keywords(k, col)\n",
    "        jel_kwcnt[col].loc[jel_codes, kws] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def associated_jel_codes(keywords, extractor, cnt_threshold=10):\n",
    "    sum_vector = jel_kwcnt[extractor][keywords].sum(axis=1)\n",
    "    sum_vector[sum_vector < cnt_threshold] = 0\n",
    "    sum_vector[sum_vector >= cnt_threshold] = 1\n",
    "    return sum_vector\n",
    "\n",
    "def associated_keywords(jels, extractor):\n",
    "    sum_vector = jel_kwcnt[extractor].loc[jels].sum()\n",
    "    sum_vector[sum_vector > 0] = 1\n",
    "    return sum_vector\n",
    "\n",
    "def to_binary(x, y):\n",
    "    labels = list(set(x).union(set(y)))\n",
    "    return np.isin(labels, x), np.isin(labels, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run diversity experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dumping_factor = 150000\n",
    "thresholds = [floor(jel_kwcnt[extr].sum().sum()/dumping_factor)\n",
    "    for extr in keyword_extractors]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what one trial is looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_similarity_score\n",
    "thresholds = (10, 20, 5)\n",
    "idx = doc_kw_mapping.index[randint(0, len(doc_kw_mapping)-1)]\n",
    "actual_jels = df.loc[idx][\"classification_jel\"]\n",
    "print(f\"actual jels: {actual_jels}\")\n",
    "\n",
    "\n",
    "for extr, threshold in zip(keyword_extractors, thresholds):\n",
    "    keywords = extract_keywords(idx, extr)\n",
    "    candidates = associated_jel_codes(keywords, extr, cnt_threshold=threshold)\n",
    "    candidates = candidates[candidates == 1]\n",
    "    \n",
    "    score = jaccard_similarity_score(*to_binary(actual_jels, candidates.index))\n",
    "    print(f\"{extr}: {score}\")\n",
    "    c = candidates.index\n",
    "    print(f\"candidates: {c}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = defaultdict(list)\n",
    "trials = 10000\n",
    "for _ in range(trials):\n",
    "    idx = doc_kw_mapping.index[randint(0, len(doc_kw_mapping)-1)]\n",
    "    actual_jels = df.loc[idx][\"classification_jel\"]\n",
    "\n",
    "    for extr, threshold in zip(keyword_extractors, thresholds):\n",
    "        keywords = extract_keywords(idx, extr)\n",
    "        candidates = associated_jel_codes(keywords, extr, cnt_threshold=threshold)\n",
    "        candidates = candidates[candidates == 1]\n",
    "\n",
    "        score = jaccard_similarity_score(*to_binary(actual_jels, candidates.index))\n",
    "        results[extr].append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean, variance\n",
    "m, v = mean(results['LSI']), variance(results['LSI'])\n",
    "print(f\"LSI/Rank\\nmean: {m}\\nvariance: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = mean(results['TFIDF']), variance(results['TFIDF'])\n",
    "print(f\"TFIDF\\nmean: {m}\\nvariance: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m, v = mean(results['TextRank']), variance(results['TextRank'])\n",
    "print(f\"TextRank\\nmean: {m}\\nvariance: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keywords(kwds):\n",
    "    return Counter(chain(*(kw for kw in kwds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 500\n",
    "keywords = pd.DataFrame(index=range(trials), columns=keyword_extractors.keys())\n",
    "opposing_collections = namedtuple(\"opposing_collections\", [\"light\", \"dark\"])\n",
    "\n",
    "for trial_num in range(trials):\n",
    "    coll_a, coll_b = collections.disjoint_collections(size=10, degree=5)\n",
    "    for extractor_name, extractor in keyword_extractors.items():\n",
    "        kwds_a = []\n",
    "        kwds_b = []\n",
    "        for idx_a, idx_b in zip(coll_a, coll_b):\n",
    "            kwds_a.append(extractor.keywords(idx_to_text(idx_a)))\n",
    "            kwds_b.append(extractor.keywords(idx_to_text(idx_b)))\n",
    "            \n",
    "        keywords.loc[trial_num, extractor_name] = opposing_collections(\n",
    "            count_keywords(kwds_a),\n",
    "            count_keywords(kwds_b)\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's look at an excerpt of the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(min(10, trials)):\n",
    "    print(f\"document #{idx}\")\n",
    "    for extractor in keyword_extractors.keys():\n",
    "        light_kwds = set([k for k, _ in keywords.loc[idx, extractor].light.most_common()])\n",
    "        dark_kwds = set([k for k, _ in keywords.loc[idx, extractor].dark.most_common()])\n",
    "\n",
    "        i = len(light_kwds.intersection(dark_kwds))\n",
    "        d = len(light_kwds.symmetric_difference(dark_kwds))\n",
    "        print(f\"{extractor}\\nintersection: {i}\\ndifference: {d}\\n\")\n",
    "    print(\"#######################\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_result = namedtuple(\"diversity_result\", [\"intersection_length\", \"difference_length\"])\n",
    "diversity_results = {k: [] for k in keyword_extractors}\n",
    "\n",
    "for idx in range(trials):\n",
    "    for extractor in keyword_extractors.keys():\n",
    "        light_kwds = set([k for k, _ in keywords.loc[idx, extractor].light.most_common()])\n",
    "        dark_kwds = set([k for k, _ in keywords.loc[idx, extractor].dark.most_common()])\n",
    "        \n",
    "        diversity_results[extractor].append(diversity_result(\n",
    "            len(light_kwds.intersection(dark_kwds)),\n",
    "            len(light_kwds.symmetric_difference(dark_kwds))\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for extractor in keyword_extractors.keys():\n",
    "    i = mean((r.intersection_length for r in diversity_results[extractor]))\n",
    "    d = mean((r.difference_length for r in diversity_results[extractor]))\n",
    "    print(f\"{extractor}\\nmean keyword intersection per collection duo: {i:.1f}\")\n",
    "    print(f\"mean keyword difference size per collection duo: {d:.1f}\\nintersection share: {100*(i/d):.1f}%\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
